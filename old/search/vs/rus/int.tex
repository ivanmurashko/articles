\chapter{Внутреннее устройство типичного поискового движка}
Типичный поисковик состоит из трех основных частей
(см. рис. \ref{figScheme}): {\bf Index}, {\bf DB}  и {\bf
  Search}. {\bf Index} проходит по интернету, скачивает документы, 
разбирает их содержимое и сбрасывает его в базу. {\bf Database} хранит 
некоторые данные по которым можно будет выдать информацию
пользователю, соответствующую его
поисковому запросу. Кроме того база данных хранит информацию которая
необходима для индексирования (параметры индексирования) а также может
хранить статистическую информацию собираемую при поиске. {\bf Search}
предназначен для формирования ответа пользователю из данных хранящихся
в {\bf DB}. 
\begin{figure}
\begin{center}
\includegraphics{./scheme.eps}
\end{center}
\caption{Scheme}
\label{figScheme}
\end{figure}

\section{Index}
Другие названия: индексер, crawler, паук. Состоит из следующих
основных частей:  {\bf scheduler} (планировщик), {\bf loader}, {\bf
parser} (см. рис. \ref{figIndex}). 

\begin{figure}
\begin{center}
\includegraphics{./index.eps}
\end{center}
\caption{Index}
\label{figIndex}
\end{figure}

{\bf Scheduler} достает документы из базы и отдает их {\bf
loader} при этом он проставляет для этих документов в базе такую
информацию как время последнего индексирования и время следующего
индексирования. 
Чаще всего на этом этапе для документа известен только его
URL и параметры его индексирования:
\begin{itemize}
\item Максимальное ``число кликов мышью'' которое допустимо для
  данного URL
\item Ссылка на информацию о параметрах индексирования сайта к которому
  относится данный URL (данная ссылка может быть так же получена по
  самому URL, отпарсив который можно определить сервер а вместе с ним
  и информацию о параметрах индексирования)
\end{itemize}
Параметры индексирования сайта: 
\begin{itemize}
\item Ходить или нет на другие сайты с этого
\item Какое максимальное число документов обрабатывать с этого сайта
\item Глубина индексирования сайта (на сколько каталогов спускаться
  вниз)
\end{itemize} 
Кроме этого существуют также глобальные параметры. Например в
mnoGoSearch и в ASPSeek  существует такая опция как MaxDocSize которая
задает максимальный размер скачиваемого документа. Все что больше
указаного размера - обрезается.

{\bf Loader} в соответствии с параметрами индексирования (например:
MaxDocSize)  а также в зависимости от схемы в имени URL (http, https,
ftp, ...) производит скачивание документа. При этом получается
некоторая первичная информация о документе. Например в случае HTTP
это статус (200 - ok, 404 -not found, ...), время последней
модификации документа и т. п. - все то что может быть получено из http
ответа сервера. В дальнейшем документ отдается на обработку в {\bf
  parser}

{\bf Parser} производит обработку в зависимости от типа документа
(html, pdf, doc, ...). В общем случае для всех типов документов
обработка однотипна. {\bf Parser} собирает информацию о каждом слове
документа: в какой позиции данное слово встретилось и некоторую
информация о данной позиции (в случае html - в каких тегах находится
данная позиция).
Кроме того {\bf parser}  собирает информацию о всех ссылках на другие
документы (тег <a href>) и в зависимости от параметров индексирования
(максимальное число документов с сайта, число ``кликов мышью'', ...),
решает сохранять эту информацию или нет (добавлять данные ссылки в
базу для последующей индексации или нет).  

После данной обработки вся собранная {\bf loader} и {\bf parser}
информация сохраняется в базе данных.

Чаще всего, с целью увеличения быстродействия, связка  {\bf loader} и
{\bf parser} работает как отдельный поток. При этом {\bf scheduler}
следит за распределением задач между потоками. В частности, следит
чтобы не было необоснованно много соединений с одним сервером (polite
robot). 

\section{Search}
Состоит из двух основных частей: поискового демона (searchd) и
некоторого web-application (cgi  программа на  c, php, perl, asp,
etc.). В случае простейшей базы данных (mnoGoSearch) все операции по
обработке поисковых запросов могут быть произведены без участия
поискового демона. Вполне естественно, что наибольший интерес
представляет именно поисковый демон. 

Так как общение между демоном и  web-application
производится посредством некоторого протокола, то демон должен
включать в себя модуль который отвечает за прием и отправку
данных в соответствии с указанным протоколом. 

Для каждого слова из поискового запроса должен быть получен список
документов на которых данное слово встретилось. В дальнейшем должны
быть оставлены только те документы на которых встречаются все
слова. Для каждого документа из оставшегося списка должна быть
просчитана релевантность. Весь список должен быть отсортирован по
релевантности и выдан пользователю. 

Ускорить работу поиска можно путем добавления некоторого кэша который
содержит обработанные данные для наиболее популярных запросов. 

\section{Database}
Наиболее важная часть поисковика которая отвечает за его
производительность. Прежде чем рассматривать внутреннее устройство базы
данных следует определится с тем какого типа информацию сохраняет {\bf
Index} и какую информацию из базы получает {\bf Search}. 

{\bf Index} имеет дело с документами, которые чаще всего представлены
в базе в виде следующей таблицы:
\begin{center}
\begin{longtable}{|c|c|c|} 
\caption{Table urls}\\
\hline
url\_id & url & параметры индексирования \\ \hline
1 & http://www.site.com/page.htm & ... \\ \hline
... & ... & ... \\ \hline
12 & http://www.site.com/12.htm & ... \\ \hline
... & ... & ... \\ 
\end{longtable}
\end{center}
Для каждого документа из этой таблицы, {\bf Index} должен занести все
слова в нем содержащиеся вместе с информацией об этих словах. Данная
информация так называемая  relevancy info - говорит нам о том в каких
частях документа встретилось данное слово (в каких тэгах). Очевидно
что если слово встретилось в <title> и в <body> странички, то оно
будет иметь больший вес чем слово которое встретилось только в <body>
странички. Кроме того должны быть занесены все позиции слова в данном
документе. Это с одной стороны даст нам информацию о встречаемости
слова на страничке (очевидно, хотя не всегда, что слово с большей
встречаемостью должно иметь больший вес). С другой стороны это поможет
нам в определении взаимного расположения слов на документе при поиске
фраз - дистанцию между словами. Очевидно что при поиске фраз - фразы с
наименьшей дистанцией должны иметь больший вес.  

{\bf Search} имеет дело со словами объединеными в следующую таблицу:
\begin{center}
\begin{longtable}{|c|c|} 
\caption{Table words}\\
\hline
word\_id & word \\ \hline
1 & first \\ \hline
... & ... \\ \hline
10 & ten  \\ \hline
... & ... \\ 
\end{longtable}
\end{center}
Для каждого слова из поискового запроса, {\bf Search} должен
определить все документы на которых данное слово встречалось. Далее
должен оставить только те документы на которых встречались все слова,
сосчитать для каждого документа relevancy  и отсортировать по этому
критерию. 

\subsection{Использование реляционной базы данных}
Наиболее простейший путь использует {\bf mnoGoSearch}, который создает
следующую таблицу 
\begin{center}
\begin{longtable}{|c|c|c|c|} 
\caption{Table dict}\\
\hline
rec\_id & word\_id & url\_id & relevancy info\\ \hline
1 & 10 & 12 & ... \\ \hline
... & ... & ... & ... \\ 
\end{longtable}
\end{center}
Данная таблица говорит, что слово ``ten'' (word\_id - 10) присутствует в
документе ``http://www.site.com/12.htm'' (url\_id - 12). Таким образом
{\bf Index} имеет дело с записями из этой таблицы с одинаковыми
url\_id. {\bf Search} имеет дело с записями с одинаковыми word\_id.

Данный путь имеет 2 основных недостатка. Прежде чем начать их
обсуждение мне хотелось бы сделать следующее замечание: я тестировал
работу данного поисковика на базе данных  MySQL. Очень может быть, что
указанные недостатки имеют своей причиной именно  MySQL (например,
может быть стоит использовать Oracle).

{\bf Первый недостаток} связан с тем что при операциях изменения
данных (INSERT, DELETE, UPDATE) MySQL блокирует доступ к данным из
других приложений. Когда данных не много - такие блокировки не особо
заметны, но при большом количестве данных - начинает тормозить как
{\bf Index} так и {\bf Search}. Для решения этой проблемы mnoGoSearch
предлагает особый режим работы (Storage mode - multi) в котором
таблица dict разбивается на несколько похожих таблиц. Данные таблицы
имеют туже структуру что и оригинальная таблица dict, но слова в них
сгруппированы по некоторому критерию. Например пусть число разбиений
256. Имена таблиц состоят из имени  dict и порядкового номера (dict00
- dictFF).  Номер таблицы определяется следующей формулой: 
\[
N = word\_id \quad mod \quad 256.
\]

{\bf Второй недостаток} более существенен и связан с тем что  MySQL
работает достаточно быстро если индекс базы данных целиком умещается в
RAM. В этом случае число обращений к жесткому диску минимально и поиск
осуществляется достаточно быстро. Но наблюдалась следующая картина -
когда индекс базы данных переставал умещаться в  RAM -
производительность системы резко падала. Можно произвести следующую
оценку размера индекса. Целочисленный индекс в MySQL занимает примерно
10 байт. В таблице dict - два целочисленных индекса: по полям word\_id
и url\_id. Таким образом суммарный размер индекса для одной записи - 20
байт. В среднем документ в интернете содержит 200 уникальных
слов. В соответствии с требованием нашего заказчика в базе должна
храниться информация по 10 000 000 документам. Следовательно размер
индекса: 
\[
size = 10^7 \cdot 200 \cdot 20 bytes = 40 Gb.
\]  
Это довольно приличный объем чтобы целиком уместится в RAM.

\subsection{Использование специализированной базы данных}
Указанные два недостатка использования реляционной базы данных -
подсказывают нам иной путь хранения данных - разделить те данные
которые обновляются {\bf Index} и те которые использует {\bf
  Search}. При этом у нас имеется как бы две базы данных IDB (index
database) (см. рис. \ref{figIDB}) и SDB (search database)
(см. рис. \ref{figSDB}). Именно такой режим работы использует по
умолчанию ASPSeek. Кроме того судя по доступной информации
(http://www.cs.wpi.edu/\~cs4241/2000d/class11.pdf), подобную схему
использует также Google, а вместе с ним и все остальные крупные
поисковики. 

Описывая далее пример реализации такой базы данных мне
хотелось бы сделать следующее замечание. В дальнейшем будет излагаться
формат хранения данных который используется мной в моей текущей
разработке. Он подобен формату используемуму ASPSeek но
не совпадает с ним. 

\begin{figure}
\begin{center}
\includegraphics{./idb.eps}
\end{center}
\caption{Index database (IDB)}
\label{figIDB}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics{./sdb.eps}
\end{center}
\caption{Search database (SDB)}
\label{figSDB}
\end{figure}

Index database представляет собой два файла URLS и Positions. В URLS
хранится информация о разных парах url\_id - word\_id. Информация о
каждой паре включает в себя собственно идентификатор: два целых числа
которые говорят к какому слову и на каком документе относится данная
информация. Кроме того к каждой паре относится ссылка на файл с
информацией о позициях слова. Offset задает смещение данных, а  size -
их размер. Каждая информация о позиции слова состоит из двух частей:
\begin{enumerate}
\item Position - некоторое число - позиция слова в документе
\item RI (relevancy info) - некоторый флаг который говорит о том в
  каких тегах (частях документа) находится данная позиция
\end{enumerate}
Таким образом {\bf Index} просто заносит в конец этих файлов новые
данные.

Search database состоит из трех файлов. Это знакомые нам URLS и
Position, а также новый файл Index, который позволяет нам быстро
находить нужную информацию. Порядок работы примерно следующий. По
некоторой хэш-функции \(H(word\_id)\) мы находим смешение в файле
индексов. В качестве хэш функции может быть выбрана следующая:
\[
H(word\_id) = word\_id \cdot 8,
\]
где 8 - размер одной записи в индексном файле. По данной записи мы
определяем смещение (offset) и размер данных (size) в файле с данными
(URLS). 

Оценим приблизительный размер индекса. Очевидно что если индекс
целиком будет в памяти - то нам необходимо будет сделать всего 2
обращения к жесткому диску чтобы достать необходимы данные. При этом,
очевидно, что информацию о позициях слова можно включить в файл
URLS. Так что число обращений к жесткому диску уменьшится до одного.

По информации Google - он хранит у себя 14 миллионов слов. Таким
образом примем максимальную оценку числа слов в \(14 \cdot 10^6\). С
учетом того что поле word\_id в таблице  words - ``integer
auto\_increment primary key'', то размер индекса будет \(\approx 107
Mb\). Допустимый размер для того чтобы поместится в RAM.

Очевидно что две эти базы данных отличаются друг от друга и необходимо
иметь такой модуль который бы осуществлял конвертацию из формата IDB в
формат SDB. Сортировка больших объемов данных и построение индекса -
довольно ресурсоемкая операция. Для того чтобы увеличить скорость ее
работы ASPSeek осуществляет предварительную сортировку уже на этапе
индексирования. Делается это следующим образом. Файл URLS из IDB
разделяется на 100 частей в разные каталоги. Номер каталога - 
\( word\_id \quad mod \quad 100 \). При этом база данных SDB также разделяется на
100 частей. Вместе с этим, очевидно меняется хэш-функция:
\[
H(word\_id) = \left[\frac{word\_id}{100}\right] \cdot 8,
\]
где \(\left[ \dots \right]\) -  операция взятия целой части.

Это помогает, но не совсем. Один мой товарищ для своей диссертации
ставил следующий эксперимент над  ASPSeek. Он заставлял ASPSeek
сканерить локально 1 000 000 документов. При этом он использовал
простейшие документы (plain text). ASPSeek устроен так что запускает
процесс конвертации после того как все документы скачены. Заняло это 5
дней. 

Но если чуть-чуть изменить режим работы и запускать
конвертацию скажем каждые полчаса - то скорость работы существенно
увеличится - до 3-4 часов. Одним из последних требований заказчика
было обеспечить подобную функциональность в VerticalSeek.

