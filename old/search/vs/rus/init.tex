\chapter{Введение}
Основной целью данной презентации будет дать вам некоторое
представление о том как организованы внутри поисковые машины, которые
осуществляют поиск информации в интернете. Существует большое
разнообразие разных поисковых машин, некоторые из них используют свои
поисковые базы данных (пример Google, yandex) другие используют
результаты выдаваемые такими поисковиками как Google для формирования
своих результатов - так называемые метапоисковики (например
http://vivisimo.com/). Некоторые поисковики осуществляют поиск по
всему интернету (Google), некоторые по его части (yandex - русский
сегмент интернета), а другие осуществляют поиск по одному сайту.

Стоит описать какие основные проблемы возникаю при реализации
поисковика. 
\begin{itemize}
\item полнота - по возможности поисковик должен осуществлять поиск по
  всем возможным документам. Т. е. на любой запрос пользователя в
  идеале должен найтись соответствующий ему ответ
\item релевантность - на некоторые запросы пользователей число
  документов им удовлетворяющее может быть очень большим. Необходимо
  иметь некоторый алгоритм который позволял бы пользователю выбирать
  из всего этого многообразия именно то что ему нужно.
\item скорость работы - скорость обработки документов и, самое главное
  - скорость вывода результатов пользователю должна быть высокой.
\end{itemize}

В данной презентации я буду делать упор в основном на первом и третьем
требовании из которых вытекает такое глобальное требование как
производительность. Релевантность остается по большей части вне данной
презентации прежде всего потому что для хорошого алгоритма просчета
релевантности нужна идея, например такая как индекс цитирования которая
позволила Google выбиться в лидеры поиска в интернет. В месте с тем
поисковая машина удовлетворяющая требованиям производительности может
быть построена на вполне стандартных и не очень сложных алгоритмах.

Прежде чем двигаться дальше стоит описать какие задачи стояли передо
мной в начале проекта. Наш заказчик WebGuerrilla хотел организовать
поиск по некоторым группам сайтов (например по средствам хранения
информации http://www.datastoragesearch.com/). Первоначальный каталог
сайтов по некоторой категории предполагалась брать из dmoz.org. Данный
ресурс представляет собой более 4,5 миллионов сайтов просмотренных
несколькими десятками тысяч редакторов (62333) и определенных в 590
000 категорий. Данные по категориям могут быть использованы в
соответствии с Open Directory License (http://dmoz.org/license.html)
и могут быть получены в виде некоторого XML файла (размер в архиве 255
Мб, разархивированный - несколько гигабайт).
Кстати, одним из самых первых заданий было -
конвертация данного файла в формат удобный для последующего занесения
в базу данных  MySQL. Заказчик сразу же подчеркнул что он не
собирается строить что-то подобное Google, вместе с тем максимальное
количество документов для индексирования было указано большим - 10
миллионов. В качестве search engine  они предполагали использовать
свободно распространяемый поисковый движок ASPSeek
(http://www.aspseek.org). В качестве базы данных использовалась
MySQL. Из бесед с заказчиком я понял что прежде чем обратиться в
Аркадию они тестировали различные свободнораспространяемые поисковики
(за пол года) и по критерию производительности их удовлетворила именно
эта связка ASPSeek-MySQL. 

Заказчику требовалось добавить некоторую дополнительную функциональность в
данный поисковик. Например одной из первоочередных задач было обеспечить
подержку данным поисковиком cookies.
